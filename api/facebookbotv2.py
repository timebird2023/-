import os
import json
import requests
import asyncio
import textwrap
import logging
import random
import urllib.parse
import io
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from flask import Flask, request
from collections import defaultdict, deque
import edge_tts

# ====================================================================
# 1. âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (Config)
# ====================================================================
class Config:
    PORT = int(os.environ.get('PORT', 25151))
    VERIFY_TOKEN = 'boykta2025'
    PAGE_ACCESS_TOKEN = 'EAAYa4tM31ZAMBPZBZBIKE5832L12MHi04tWJOFSv4SzTY21FZCgc6KSnNvkSFDZBZAbUzDGn7NDSxzxERKXx57ZAxTod7B0mIyqfwpKF1NH8vzxu2Ahn16o7OCLSZCG8SvaJ3eDyFJPiqYq6z1TXxSb0OxZAF4vMY3vO20khvq6ZB1nCW4S6se2sxTCVezt1YiGLEZAWeK9'

    _PARTIAL_KEYS = [
        "mwhCmwL1LNpcQvdMTHGvWGdyb3FYfU2hS7oMXV65vqEfROmTVr0q",
        "uKouecFAYlbnRuy0Nn2rWGdyb3FY15KRhNRZyQsBUBBugKcU8C2N",
        "jkVCijtNhFZ20uU7QTn5WGdyb3FYh2XK4b3uqYVoEN52Xjm9gN1d"
    ]
    
    MODEL_CHAT = "llama-3.1-8b-instant"
    # âœ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµØ­ÙŠØ­ Ø§Ù„Ù…ØªØ§Ø­ Ø­Ø§Ù„ÙŠØ§Ù‹
    MODEL_VISION = "llama-3.2-11b-vision-preview" 
    MODEL_AUDIO = "whisper-large-v3"

    # âœ… Ø§Ù„ØªØ¹Ø¯ÙŠÙ„: ØµÙˆØª Ø±Ø¬Ù„ (Ø´Ø§ÙƒØ±)
    # Ø®ÙŠØ§Ø±Ø§Øª Ø£Ø®Ø±Ù‰ Ù„Ù„Ø°ÙƒØ±: ar-SA-HamedNeural (Ø³Ø¹ÙˆØ¯ÙŠ)
    TTS_VOICE = "ar-EG-ShakirNeural" 

    @staticmethod
    def get_key(index=0):
        return "gsk_" + Config._PARTIAL_KEYS[index % len(Config._PARTIAL_KEYS)]

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("BoyktaBot_V8")

# ====================================================================
# 2. ğŸ§  Ø¹Ù…ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Groq Client)
# ====================================================================
class GroqClient:
    BASE_URL = "https://api.groq.com/openai/v1"

    @staticmethod
    def chat(messages, model=Config.MODEL_CHAT):
        for i in range(len(Config._PARTIAL_KEYS)):
            key = Config.get_key(i)
            try:
                resp = requests.post(
                    f"{GroqClient.BASE_URL}/chat/completions",
                    headers={"Authorization": f"Bearer {key}"},
                    json={"model": model, "messages": messages, "temperature": 0.6},
                    timeout=30
                )
                if resp.status_code == 200:
                    return resp.json()['choices'][0]['message']['content']
                # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙƒÙˆÙ†Ø³ÙˆÙ„ Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
                logger.error(f"Chat Error {resp.status_code}: {resp.text}")
            except Exception as e:
                logger.error(f"Chat Ex: {e}")
        return None

    @staticmethod
    def vision(img_url, prompt="Extract text"):
        for i in range(len(Config._PARTIAL_KEYS)):
            key = Config.get_key(i)
            try:
                headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
                payload = {
                    "model": Config.MODEL_VISION,
                    "messages": [{
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {"type": "image_url", "image_url": {"url": img_url}}
                        ]
                    }],
                    "max_tokens": 1024
                }
                
                resp = requests.post(f"{GroqClient.BASE_URL}/chat/completions", headers=headers, json=payload, timeout=45)
                
                if resp.status_code == 200:
                    return {"status": "success", "text": resp.json()['choices'][0]['message']['content']}
                else:
                    return {"status": "error", "text": f"API Error {resp.status_code}: {resp.text}"}
            except Exception as e:
                return {"status": "error", "text": str(e)}
        return {"status": "error", "text": "All keys failed"}

    @staticmethod
    def audio_transcription(audio_url):
        try:
            audio_data = requests.get(audio_url).content
            key = Config.get_key(0)
            files = {
                'file': ('audio.mp3', audio_data, 'audio/mpeg'),
                'model': (None, Config.MODEL_AUDIO)
            }
            headers = {"Authorization": f"Bearer {key}"}
            resp = requests.post(f"{GroqClient.BASE_URL}/audio/transcriptions", headers=headers, files=files, timeout=60)
            if resp.status_code == 200:
                return resp.json().get('text', '')
            return None
        except:
            return None

# ====================================================================
# 3. ğŸ› ï¸ Ø§Ù„Ø£Ø¯ÙˆØ§Øª (Tools)
# ====================================================================
class Tools:
    @staticmethod
    def render_latex(latex):
        try:
            clean = latex.replace('$$', '').strip()
            fig, ax = plt.subplots(figsize=(10, 2))
            fig.patch.set_alpha(0)
            ax.axis('off')
            ax.text(0.5, 0.5, f"${clean}$", size=20, ha='center', va='center')
            buf = io.BytesIO()
            plt.savefig(buf, format='png', bbox_inches='tight', dpi=150)
            plt.close(fig)
            buf.seek(0)
            return buf.getvalue()
        except: return None

    @staticmethod
    def generate_image(prompt):
        try:
            safe_prompt = urllib.parse.quote(prompt)
            url = f"https://image.pollinations.ai/prompt/{safe_prompt}?width=1024&height=1024&model=flux&seed={random.randint(1,99999)}"
            return requests.get(url, timeout=30).content
        except: return None

    @staticmethod
    def text_to_speech(text):
        async def _run():
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… ØµÙˆØª Ø§Ù„Ø±Ø¬Ù„ (Shakir)
            comm = edge_tts.Communicate(text, Config.TTS_VOICE)
            out = io.BytesIO()
            async for chunk in comm.stream():
                if chunk["type"] == "audio": out.write(chunk["data"])
            out.seek(0)
            return out
        try: return asyncio.run(_run())
        except: return None

# ====================================================================
# 4. ğŸ§  Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…Ø¯Ø¨Ø± (Smart Brain)
# ====================================================================
class BotLogic:
    def __init__(self):
        self.users = defaultdict(lambda: {
            'history': deque(maxlen=10), # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù‚Ù„ÙŠÙ„Ø§Ù‹
            'img_context': None
        })

    def process_text(self, user_id, text, is_voice_msg=False):
        user_data = self.users[user_id]
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ù„Ø§Ø­Ø¸Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©
        voice_hint = "[User sent a Voice Note]: " if is_voice_msg else ""
        
        # âœ… Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø°ÙƒÙŠ (Smart System Prompt)
        # ÙŠØ¹Ù„Ù… Ø§Ù„Ø¨ÙˆØª Ù…ØªÙ‰ ÙŠÙ†ÙØ° Ø§Ù„Ø£Ù…Ø± ÙˆÙ…ØªÙ‰ ÙŠÙ†ØªØ¸Ø± Ø§Ù„ØªÙØ§ØµÙŠÙ„
        system_prompt = f"""
        Ø£Ù†Øª (Boykta)ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø¬Ø²Ø§Ø¦Ø±ÙŠ.
        
        ğŸš¨ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù‡Ø§Ù…Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ù„Ø³ÙŠØ§Ù‚:
        1. **Ø§Ù„ØµÙˆØ± (Images):**
           - Ø¥Ø°Ø§ Ø³Ø£Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… "Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø±Ø³Ù…ØŸ"ØŒ Ø£Ø¬Ø¨ Ø¨Ù€ "Ù†Ø¹Ù…ØŒ Ù…Ø§Ø°Ø§ Ø£Ø±Ø³Ù…ØŸ" (Ù„Ø§ ØªØ±Ø³Ù„ Ø£Ù…Ø± Ø§Ù„Ø±Ø³Ù…).
           - ÙÙ‚Ø· Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ¹Ø·ÙŠÙƒ ÙˆØµÙØ§Ù‹ Ù„Ù„ØµÙˆØ±Ø©ØŒ Ø£Ø±Ø³Ù„ Ø§Ù„Ø£Ù…Ø±: `CMD_IMAGE: <English Description>`
           
        2. **Ø§Ù„ØµÙˆØª (Audio):**
           - Ø¥Ø°Ø§ Ø³Ø£Ù„ "Ù‡Ù„ ØªØªÙƒÙ„Ù…ØŸ"ØŒ Ø£Ø¬Ø¨ Ø¨Ù€ "Ù†Ø¹Ù…ØŒ Ù…Ø§Ø°Ø§ Ø£Ù‚ÙˆÙ„ØŸ"
           - ÙÙ‚Ø· Ø¹Ù†Ø¯Ù…Ø§ ÙŠØ·Ù„Ø¨ Ù‚Ø±Ø§Ø¡Ø© Ù†Øµ Ù…Ø¹ÙŠÙ†ØŒ Ø£Ø±Ø³Ù„: `CMD_AUDIO: <Text>`

        3. **Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ§Øª:**
           - Ø§Ø³ØªØ®Ø¯Ù… `CMD_MATH: <LaTeX>` Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© ÙÙ‚Ø·.

        Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙŠØ§Ù‚ (ØµÙˆØ±Ø© Ø³Ø§Ø¨Ù‚Ø©): {user_data['img_context'] or 'Ù„Ø§ ÙŠÙˆØ¬Ø¯'}
        """
        
        # Ø¯Ù…Ø¬ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ø¹ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        msgs = [{"role": "system", "content": system_prompt}] + list(user_data['history']) + [{"role": "user", "content": voice_hint + text}]
        
        reply = GroqClient.chat(msgs)
        
        if reply:
            # Ø­ÙØ¸ Ø§Ù„Ø±Ø¯ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ® (Ù…Ø§ Ø¹Ø¯Ø§ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØªÙ‚Ù†ÙŠØ© Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù†Ø¸Ø§ÙØ© Ø§Ù„Ø°Ø§ÙƒØ±Ø©)
            if "CMD_" not in reply:
                user_data['history'].append({"role": "user", "content": text})
                user_data['history'].append({"role": "assistant", "content": reply})
            else:
                # Ù†Ø­ÙØ¸ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ù„ÙŠØ¹Ø±Ù Ø§Ù„Ø¨ÙˆØª Ù…Ø§Ø°Ø§ Ø·Ù„Ø¨ Ø³Ø§Ø¨Ù‚Ø§Ù‹
                user_data['history'].append({"role": "user", "content": text})
                
            return reply
        return "Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„."

bot = BotLogic()

# ====================================================================
# 5. ğŸŒ Ø®Ø§Ø¯Ù… ÙÙŠØ³Ø¨ÙˆÙƒ (Facebook Server)
# ====================================================================
app = Flask(__name__)
FB_API = "https://graph.facebook.com/v19.0/me/messages"

def fb_send(uid, payload, files=None):
    url = f"{FB_API}?access_token={Config.PAGE_ACCESS_TOKEN}"
    if files:
        requests.post(url, data=payload, files=files)
    else:
        requests.post(url, json=payload)

def send_text(uid, txt, quick_replies=None):
    if not txt: return
    chunks = textwrap.wrap(txt, 1900, replace_whitespace=False)
    for i, chunk in enumerate(chunks):
        msg_data = {'text': chunk}
        if i == len(chunks) - 1 and quick_replies:
            msg_data['quick_replies'] = [{"content_type": "text", "title": k, "payload": v} for k, v in quick_replies.items()]
        fb_send(uid, {'recipient': {'id': uid}, 'message': msg_data})

def send_file(uid, data, type='image'):
    fname = 'img.png' if type == 'image' else 'aud.mp3'
    mime = 'image/png' if type == 'image' else 'audio/mpeg'
    payload = {'recipient': json.dumps({'id': uid}), 'message': json.dumps({'attachment': {'type': type, 'payload': {}}})}
    fb_send(uid, payload, files={'filedata': (fname, data, mime)})

@app.route('/webhook', methods=['GET', 'POST'])
def webhook():
    if request.method == 'GET':
        return request.args.get('hub.challenge') if request.args.get('hub.verify_token') == Config.VERIFY_TOKEN else 'Error'

    if request.method == 'POST':
        data = request.get_json()
        if data['object'] == 'page':
            for entry in data['entry']:
                for event in entry.get('messaging', []):
                    if 'message' in event:
                        sender_id = event['sender']['id']
                        fb_send(sender_id, {'recipient': {'id': sender_id}, 'sender_action': 'typing_on'})
                        handle_event(sender_id, event['message'])
        return 'OK'

def handle_event(uid, msg):
    # Ù„Ø§ÙŠÙƒ ğŸ‘
    if msg.get('sticker_id'):
        send_text(uid, "ğŸ‘")
        return

    # Ù…Ø±ÙÙ‚Ø§Øª
    if 'attachments' in msg:
        atype = msg['attachments'][0]['type']
        url = msg['attachments'][0]['payload']['url']

        # 1. ØµÙˆØ± ğŸ–¼ï¸
        if atype == 'image':
            if msg.get('sticker_id'): return
            send_text(uid, "Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©... ğŸ‘ï¸")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ø¨Ø³ÙŠØ· Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ 11b
            res = GroqClient.vision(url, "Extract all text from this image perfectly. If no text, describe the image.")
            
            if res['status'] == 'success':
                bot.users[uid]['img_context'] = res['text']
                btns = {"ğŸ“ Ø­Ù„": "Ø­Ù„ Ù‡Ø°Ø§", "ğŸ“„ Ø§Ø³ØªØ®Ø±Ø§Ø¬": "Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù†Øµ", "ğŸ¨ ÙˆØµÙ": "ØµÙ Ø§Ù„ØµÙˆØ±Ø©"}
                send_text(uid, "Ù‚Ø±Ø£Øª Ø§Ù„ØµÙˆØ±Ø©! Ù…Ø§Ø°Ø§ Ø£ÙØ¹Ù„ØŸ", quick_replies=btns)
            else:
                send_text(uid, f"âš ï¸ Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {res['text']}")
            return

        # 2. ØµÙˆØª ğŸ™ï¸
        elif atype == 'audio':
            send_text(uid, "Ø£Ø³Ù…Ø¹Ùƒ... ğŸ§")
            text_voice = GroqClient.audio_transcription(url)
            if text_voice:
                send_text(uid, f"ğŸ¤ {text_voice}") # ØªØ£ÙƒÙŠØ¯ Ù…Ø§ Ø³Ù…Ø¹Ù‡
                # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù†Øµ Ù„Ù„Ø¨ÙˆØª Ù„ÙŠØ±Ø¯ Ø¹Ù„ÙŠÙ‡
                process_bot_response(uid, text_voice, is_voice=True)
            else:
                send_text(uid, "Ø§Ù„ØµÙˆØª ØºÙŠØ± ÙˆØ§Ø¶Ø­.")
            return

    # Ù†ØµÙˆØµ
    text = msg.get('text')
    if text:
        process_bot_response(uid, text)

def process_bot_response(uid, text, is_voice=False):
    # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ø°ÙƒØ§Ø¡
    response = bot.process_text(uid, text, is_voice_msg=is_voice)

    # ØªÙ†ÙÙŠØ° Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…Ø¶Ù…Ù†Ø©
    if "CMD_IMAGE:" in response:
        prompt = response.split("CMD_IMAGE:")[1].strip()
        send_text(uid, f"Ø¬Ø§Ø±ÙŠ Ø±Ø³Ù…: {prompt} ğŸ¨")
        img = Tools.generate_image(prompt)
        if img: send_file(uid, img, 'image')
        else: send_text(uid, "ÙØ´Ù„ Ø§Ù„Ø±Ø³Ù….")

    elif "CMD_AUDIO:" in response:
        txt = response.split("CMD_AUDIO:")[1].strip()
        send_text(uid, "Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¯Ø«... ğŸ—£ï¸") # Ø¥Ø´Ø¹Ø§Ø± Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø±Ø³Ø§Ù„
        aud = Tools.text_to_speech(txt)
        if aud: send_file(uid, aud, 'audio')
        else: send_text(uid, "ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª.")

    elif "CMD_MATH:" in response:
        latex = response.split("CMD_MATH:")[1].strip()
        img = Tools.render_latex(latex)
        if img: 
            send_text(uid, "Ø§Ù„Ø­Ù„ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠ:")
            send_file(uid, img, 'image')
        else: 
            send_text(uid, latex)

    else:
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø¯ Ù†ØµÙŠØ§Ù‹ ÙˆØ§Ù„Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© ÙƒØ§Ù†Øª ØµÙˆØªÙŠØ© -> Ù‡Ù„ ØªØ±ÙŠØ¯ Ø§Ù„Ø±Ø¯ ØµÙˆØªÙŠØ§Ù‹ØŸ
        # Ù‡Ø°Ù‡ Ù…ÙŠØ²Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ø°ÙƒÙŠØ©: Ø¥Ø°Ø§ ÙƒÙ„Ù…ØªÙ‡ Ø¨Ø§Ù„ØµÙˆØªØŒ ÙŠÙ…ÙƒÙ†Ù‡ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„ØµÙˆØª Ø§Ø®ØªÙŠØ§Ø±ÙŠØ§Ù‹
        # Ø­Ø§Ù„ÙŠØ§Ù‹ Ù†Ø±Ø³Ù„ Ù†ØµØ§Ù‹ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù„Ù„Ø³Ø±Ø¹Ø©
        send_text(uid, response)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=Config.PORT)
