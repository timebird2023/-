import os
import json
import requests
import asyncio
import textwrap
import logging
import random
import urllib.parse
import io
import re
import matplotlib
# ÙˆØ¶Ø¹ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø§Ù„ØµØ§Ù…Øª Ù„Ù„Ø±Ø³Ù…
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from flask import Flask, request
from collections import defaultdict, deque
import edge_tts

# ====================================================================
# 1. âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (The Engine Room)
# ====================================================================
class Config:
    PORT = int(os.environ.get('PORT', 25151))
    VERIFY_TOKEN = 'boykta2025'
    PAGE_ACCESS_TOKEN = 'EAAYa4tM31ZAMBPZBZBIKE5832L12MHi04tWJOFSv4SzTY21FZCgc6KSnNvkSFDZBZAbUzDGn7NDSxzxERKXx57ZAxTod7B0mIyqfwpKF1NH8vzxu2Ahn16o7OCLSZCG8SvaJ3eDyFJPiqYq6z1TXxSb0OxZAF4vMY3vO20khvq6ZB1nCW4S6se2sxTCVezt1YiGLEZAWeK9'

    # ğŸ”’ Ø­Ù…Ø§ÙŠØ© Ø§Ù„Ù…ÙØ§ØªÙŠØ­ (Ù…ÙØµÙˆÙ„Ø©)
    _PARTIAL_KEYS = [
        "mwhCmwL1LNpcQvdMTHGvWGdyb3FYfU2hS7oMXV65vqEfROmTVr0q",
        "uKouecFAYlbnRuy0Nn2rWGdyb3FY15KRhNRZyQsBUBBugKcU8C2N",
        "jkVCijtNhFZ20uU7QTn5WGdyb3FYh2XK4b3uqYVoEN52Xjm9gN1d"
    ]
    
    # ğŸš¨ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø£Ù‚ÙˆÙ‰ (90b) ÙƒØ®ÙŠØ§Ø± ÙˆØ­ÙŠØ¯ Ù„Ù„Ø±Ø¤ÙŠØ© Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¯Ù‚Ø©
    MODEL_CHAT = "llama-3.1-8b-instant"
    MODEL_VISION = "llama-3.2-90b-vision-preview" 

    @staticmethod
    def get_key(index):
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØªØ§Ø­ Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„ ÙÙ‚Ø· Ù„Ø®Ø¯Ø§Ø¹ GitHub
        return "gsk_" + Config._PARTIAL_KEYS[index % len(Config._PARTIAL_KEYS)]

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(message)s')
logger = logging.getLogger("BoyktaBot_V6_Stable")

# ====================================================================
# 2. ğŸ§  Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¨ØµØ±ÙŠ ÙˆØ§Ù„Ù„ØºÙˆÙŠ (AI Core)
# ====================================================================
class AIService:
    def __init__(self):
        self.users = defaultdict(lambda: {'history': deque(maxlen=6), 'extracted_text': None})

    def _call_groq(self, messages, model, temp=0.5):
        """Ø¯Ø§Ù„Ø© Ø§ØªØµØ§Ù„ Ù‚ÙˆÙŠØ© Ù…Ø¹ ØªØ¯ÙˆÙŠØ± Ø§Ù„Ù…ÙØ§ØªÙŠØ­"""
        for i in range(len(Config._PARTIAL_KEYS)):
            key = Config.get_key(i)
            try:
                headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
                # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù€ tokens Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø¨ØµØ±ÙŠ Ù„ÙŠÙ‚Ø±Ø£ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
                max_tokens = 2048 if "vision" in model else 1024
                payload = {"model": model, "messages": messages, "temperature": temp, "max_tokens": max_tokens}
                
                resp = requests.post("https://api.groq.com/openai/v1/chat/completions", 
                                   json=payload, headers=headers, timeout=45) # Ø²ÙŠØ§Ø¯Ø© ÙˆÙ‚Øª Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±
                
                if resp.status_code == 200:
                    content = resp.json()['choices'][0]['message']['content']
                    if content: return content
                else:
                    logger.warning(f"Groq Fail ({model}) Status: {resp.status_code}")
            except Exception as e:
                logger.error(f"Groq Error: {e}")
        return None

    def extract_text_from_image(self, user_id, img_url):
        """
        Ù…Ø­Ø±Ùƒ OCR Ø§Ù„Ù…Ø·ÙˆØ± (V6): ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø£Ù‚ÙˆÙ‰ Ø¨ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ø±Ù†Ø©.
        """
        # ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ø¨Ø³Ø·Ø© Ø¬Ø¯Ø§Ù‹ Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø§Ù„ÙØ´Ù„
        prompt = """
        Describe this image in detail. 
        If it contains text, write it out EXACTLY as it appears. 
        If it contains math, write the equations in LaTeX.
        If it's just a photo, describe what you see.
        """
        msg = [{"role": "user", "content": [{"type": "text", "text": prompt}, {"type": "image_url", "image_url": {"url": img_url}}]}]
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù‚ÙˆÙŠ Ù…Ø¨Ø§Ø´Ø±Ø©
        extracted = self._call_groq(msg, Config.MODEL_VISION)
        
        if extracted:
            self.users[user_id]['extracted_text'] = extracted
            return True
        return False

    def chat_brain(self, user_id, user_input, task_type="chat"):
        user_data = self.users[user_id]
        context_text = user_data.get('extracted_text', '')

        if task_type == "solve":
            sys_prompt = f"""
            Ø£Ù†Øª Ø£Ø³ØªØ§Ø° ÙÙŠØ²ÙŠØ§Ø¡ ÙˆØ±ÙŠØ§Ø¶ÙŠØ§Øª Ø¬Ø²Ø§Ø¦Ø±ÙŠ Ù…Ø­ØªØ±Ù.
            Ù„Ø¯ÙŠÙƒ Ù†Øµ ØªÙ…Ø±ÙŠÙ† Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† ØµÙˆØ±Ø©:
            ---
            {context_text}
            ---
            Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: Ø­Ù„ Ù‡Ø°Ø§ Ø§Ù„ØªÙ…Ø±ÙŠÙ† Ø­Ù„Ø§Ù‹ Ù†Ù…ÙˆØ°Ø¬ÙŠØ§Ù‹ Ù…ÙØµÙ„Ø§Ù‹ (Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©).
            - Ø§Ø³ØªØ®Ø¯Ù… LaTeX Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ù…Ø­Ø§Ø·Ø© Ø¨Ù€ $$. Ù…Ø«Ø§Ù„: $$ E = mc^2 $$
            - Ø§Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„ÙØ±Ù†Ø³ÙŠØ© (Ø§Ù„Ù…ØµØ·Ù„Ø­Ø§Øª Ø§Ù„Ø¹Ù„Ù…ÙŠØ©) ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„Ù…Ù†Ù‡Ø¬ Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±ÙŠ.
            """
        elif task_type == "translate":
            sys_prompt = f"ØªØ±Ø¬Ù… Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© ØªØ±Ø¬Ù…Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ©:\n{context_text}"
        else:
            sys_prompt = f"""
            Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ (Boykta).
            - Ù„Ù„Ø±Ø³Ù…: `CMD_IMAGE: <English Prompt>`
            - Ù„Ù„ØµÙˆØª: `CMD_AUDIO: <Text>`
            Ø³ÙŠØ§Ù‚ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚: {context_text}
            """

        msgs = [{"role": "system", "content": sys_prompt}] + list(user_data['history']) + [{"role": "user", "content": user_input}]
        
        reply = self._call_groq(msgs, Config.MODEL_CHAT)
        
        if reply and task_type == "chat" and "CMD_" not in reply:
            user_data['history'].append({"role": "user", "content": user_input})
            user_data['history'].append({"role": "assistant", "content": reply})
            
        return reply

ai = AIService()

# ====================================================================
# 3. ğŸ¨ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ÙˆØ³Ø§Ø¦Ø· (Media Tools)
# ====================================================================
class MediaTools:
    @staticmethod
    def render_latex(latex_formula):
        try:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„ÙƒÙˆØ¯
            clean_tex = latex_formula.replace('$$', '').replace(r'\[', '').replace(r'\]', '').strip()
            if not clean_tex: return None
            
            fig, ax = plt.subplots(figsize=(10, 2)) # Ø¹Ø±Ø¶ Ø£ÙƒØ¨Ø± Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø·ÙˆÙŠÙ„Ø©
            fig.patch.set_alpha(0)
            ax.axis('off')
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø· Ø£ÙƒØ¨Ø±
            ax.text(0.5, 0.5, f"${clean_tex}$", size=22, ha='center', va='center')
            
            buf = io.BytesIO()
            plt.savefig(buf, format='png', bbox_inches='tight', dpi=150)
            plt.close(fig)
            buf.seek(0)
            return buf.getvalue()
        except Exception as e: 
            logger.error(f"Latex Error: {e}")
            return None

    @staticmethod
    def get_image_bytes(prompt):
        try:
            safe_p = urllib.parse.quote(prompt)
            # Ø¥Ø¶Ø§ÙØ© seed Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ØªÙƒØ±Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©
            url = f"https://image.pollinations.ai/prompt/{safe_p}?width=1024&height=1024&model=flux&seed={random.randint(1,99999)}"
            return requests.get(url, timeout=30).content
        except: return None

    @staticmethod
    def text_to_speech(text):
        async def run():
            comm = edge_tts.Communicate(text, "ar-EG-SalmaNeural")
            out = io.BytesIO()
            async for chunk in comm.stream():
                if chunk["type"] == "audio": out.write(chunk["data"])
            out.seek(0)
            return out
        try: return asyncio.run(run())
        except: return None

# ====================================================================
# 4. ğŸŒ Ù…Ø¯ÙŠØ± Ø§Ù„ÙÙŠØ³Ø¨ÙˆÙƒ (Facebook Handler)
# ====================================================================
class FB:
    URL = "https://graph.facebook.com/v19.0/me/messages"
    
    @staticmethod
    def send(user_id, data):
        requests.post(f"{FB.URL}?access_token={Config.PAGE_ACCESS_TOKEN}", json=data)

    @staticmethod
    def typing(user_id):
        FB.send(user_id, {'recipient': {'id': user_id}, 'sender_action': 'typing_on'})

    @staticmethod
    def text(user_id, msg, quick_replies=None):
        if not msg: return
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹
        chunks = textwrap.wrap(msg, 1900, replace_whitespace=False)
        for i, chunk in enumerate(chunks):
            payload = {'recipient': {'id': user_id}, 'message': {'text': chunk}}
            if i == len(chunks) - 1 and quick_replies:
                payload['message']['quick_replies'] = [{"content_type": "text", "title": k, "payload": v} for k, v in quick_replies.items()]
            FB.send(user_id, payload)

    @staticmethod
    def file(user_id, file_data, type='image'):
        files = {'filedata': ('f.png' if type=='image' else 'f.mp3', file_data, 'image/png' if type=='image' else 'audio/mpeg')}
        payload = {'recipient': json.dumps({'id': user_id}), 'message': json.dumps({'attachment': {'type': type, 'payload': {}}})}
        requests.post(f"{FB.URL}?access_token={Config.PAGE_ACCESS_TOKEN}", data=payload, files=files)

# ====================================================================
# 5. ğŸ® Ø§Ù„ØªØ­ÙƒÙ… (Controller)
# ====================================================================
app = Flask(__name__)

@app.route('/webhook', methods=['GET', 'POST'])
def webhook():
    if request.method == 'GET':
        return request.args.get('hub.challenge') if request.args.get('hub.verify_token') == Config.VERIFY_TOKEN else 'Error'

    if request.method == 'POST':
        data = request.get_json()
        if data['object'] == 'page':
            for entry in data['entry']:
                for event in entry.get('messaging', []):
                    if 'message' in event:
                        process(event['sender']['id'], event['message'])
        return 'OK'

def process(uid, msg):
    FB.typing(uid)

    if msg.get('sticker_id'):
        FB.text(uid, "ğŸ‘")
        return

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
    if 'attachments' in msg and msg['attachments'][0]['type'] == 'image':
        if msg.get('sticker_id'): return
        url = msg['attachments'][0]['payload']['url']
        FB.text(uid, "Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© (Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ù„Ø­Ø¸Ø§Øª)... ğŸ‘ï¸")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ (Ø³ØªÙ†Ø¬Ø­ Ø§Ù„Ø¢Ù† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… 90b)
        if ai.extract_text_from_image(uid, url):
            btns = {
                "ğŸ“ Ø­Ù„ Ø§Ù„ØªÙ…Ø±ÙŠÙ†": "cmd_solve", 
                "ğŸ‡¬ğŸ‡§ ØªØ±Ø¬Ù…Ø©": "cmd_translate", 
                "ğŸ“„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ": "cmd_extract",
                "ğŸ–¼ï¸ ÙˆØµÙ": "cmd_describe"
            }
            FB.text(uid, "ØªÙ… Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©! Ø§Ø®ØªØ± Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯:", quick_replies=btns)
        else:
            # ÙÙŠ Ø­Ø§Ù„ Ø§Ù„ÙØ´Ù„ Ø§Ù„Ù†Ø§Ø¯Ø± Ø¬Ø¯Ø§Ù‹
            FB.text(uid, "Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµØŒ Ù„ÙƒÙ† ÙŠÙ…ÙƒÙ†Ùƒ Ø³Ø¤Ø§Ù„ÙŠ Ø¹Ù†Ù‡ ÙŠØ¯ÙˆÙŠØ§Ù‹.")
        return

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ
    text = msg.get('text')
    if not text: return

    # Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ù† Ø§Ù„Ø£Ø²Ø±Ø§Ø±
    if text == "cmd_solve":
        FB.text(uid, "Ø¬Ø§Ø±ÙŠ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø­Ù„... ğŸ“")
        solution = ai.chat_brain(uid, "Ø­Ù„ Ø§Ù„ØªÙ…Ø±ÙŠÙ† Ø¨Ø§Ù„ØªÙØµÙŠÙ„", "solve")
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø­Ù„ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª ÙˆØ±Ø³Ù…Ù‡Ø§
        parts = re.split(r'(\$\$.*?\$\$)', solution, flags=re.DOTALL)
        for part in parts:
            if part.startswith('$$'):
                img = MediaTools.render_latex(part)
                if img: FB.file(uid, img, 'image')
            elif part.strip():
                FB.text(uid, part.strip())
        return

    elif text == "cmd_translate":
        FB.text(uid, ai.chat_brain(uid, "ØªØ±Ø¬Ù…", "translate"))
        return

    elif text == "cmd_extract":
        extracted = ai.users[uid].get('extracted_text', "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ.")
        FB.text(uid, extracted[:1900]) # Ø¥Ø±Ø³Ø§Ù„ Ø£ÙˆÙ„ 1900 Ø­Ø±Ù Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ ÙÙŠØ³Ø¨ÙˆÙƒ
        if len(extracted) > 1900: FB.text(uid, extracted[1900:])
        return
        
    elif text == "cmd_describe":
        FB.text(uid, ai.users[uid].get('extracted_text', "Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙˆØµÙ."))
        return

    # Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©
    reply = ai.chat_brain(uid, text)
    
    if reply:
        if "CMD_IMAGE:" in reply:
            FB.text(uid, "Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±Ø³Ù…... ğŸ¨")
            img = MediaTools.get_image_bytes(reply.split("CMD_IMAGE:")[1].strip())
            if img: FB.file(uid, img, 'image')
            else: FB.text(uid, "ØªØ¹Ø°Ø± Ø§Ù„Ø±Ø³Ù….")
            
        elif "CMD_AUDIO:" in reply:
            FB.text(uid, "ØªØ³Ø¬ÙŠÙ„... ğŸ™ï¸")
            aud = MediaTools.text_to_speech(reply.split("CMD_AUDIO:")[1].strip())
            if aud: FB.file(uid, aud, 'audio')
            
        elif "CMD_MATH:" in reply:
            img = MediaTools.render_latex(reply.split("CMD_MATH:")[1].strip())
            if img: FB.file(uid, img, 'image')
            
        else:
            FB.text(uid, reply)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=Config.PORT)
