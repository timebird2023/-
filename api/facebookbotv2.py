import os
import json
import requests
import asyncio
import textwrap
import logging
import random
import urllib.parse
import io
import re # ğŸ†• Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø°ÙƒØ§Ø¡
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from flask import Flask, request
from collections import defaultdict
import edge_tts

# ====================================================================
# âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
# ====================================================================

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

VERIFY_TOKEN = 'boykta2025'
PAGE_ACCESS_TOKEN = 'EAAYa4tM31ZAMBPZBZBIKE5832L12MHi04tWJOFSv4SzTY21FZCgc6KSnNvkSFDZBZAbUzDGn7NDSxzxERKXx57ZAxTod7B0mIyqfwpKF1NH8vzxu2Ahn16o7OCLSZCG8SvaJ3eDyFJPiqYq6z1TXxSb0OxZAF4vMY3vO20khvq6ZB1nCW4S6se2sxTCVezt1YiGLEZAWeK9'

# ğŸ›¡ï¸ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø¢Ù…Ù†Ø©
PARTIAL_KEYS = [
    "mwhCmwL1LNpcQvdMTHGvWGdyb3FYfU2hS7oMXV65vqEfROmTVr0q",
    "uKouecFAYlbnRuy0Nn2rWGdyb3FY15KRhNRZyQsBUBBugKcU8C2N",
    "jkVCijtNhFZ20uU7QTn5WGdyb3FYh2XK4b3uqYVoEN52Xjm9gN1d"
]
def get_key(index): return "gsk_" + PARTIAL_KEYS[index]

KEY_PRIMARY = get_key(0)
KEY_BACKUP  = get_key(1)
KEY_VISION  = get_key(2)

MODEL_CHAT   = "llama-3.1-8b-instant" 
MODEL_VISION = "meta-llama/llama-4-scout-17b-16e-instruct"

# ====================================================================
# ğŸ—„ï¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø°ÙƒÙŠØ©
# ====================================================================
user_db = defaultdict(lambda: {
    'history': [],
    'last_image_analysis': None, # Ù‡Ù†Ø§ Ù†Ø®Ø²Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©
    'last_image_url': None
})

# ====================================================================
# ğŸ¨ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø³Ù… (Math Renderer)
# ====================================================================
def render_solution_to_image(text):
    """ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ù„ØµÙˆØ±"""
    try:
        height = len(text.split('\n')) * 0.5 + 4
        if height > 50: height = 50 # Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„Ø·ÙˆÙ„
        
        fig, ax = plt.subplots(figsize=(12, height))
        ax.axis('off')
        
        # ØªØºÙ„ÙŠÙ Ø§Ù„Ù†Øµ
        wrapped_text = "\n".join(textwrap.wrap(text, width=75))
        
        ax.text(0.5, 0.5, wrapped_text, ha='center', va='center', 
                fontsize=16, family='serif', wrap=True)
        
        buf = io.BytesIO()
        plt.savefig(buf, format='png', bbox_inches='tight', dpi=150)
        plt.close(fig)
        buf.seek(0)
        return buf.getvalue()
    except Exception as e:
        logger.error(f"Render Error: {e}")
        return None

# ====================================================================
# ğŸ§  Ø¯Ù…Ø§Øº Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Groq Logic)
# ====================================================================

def call_groq(messages, model, key):
    url = "https://api.groq.com/openai/v1/chat/completions"
    headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
    try:
        res = requests.post(url, json={"model": model, "messages": messages}, headers=headers, timeout=50)
        if res.status_code in [400, 404] and "scout" in model:
             return call_groq(messages, "llama-3.2-11b-vision-preview", key)
        res.raise_for_status()
        return res.json()['choices'][0]['message']['content']
    except Exception as e:
        logger.error(f"Groq Error: {e}")
        raise e

def analyze_image(image_url):
    """Llama 4: ÙŠØ­Ù„Ù„ Ø§Ù„ØµÙˆØ±Ø© ÙˆÙŠØ³ØªØ®Ø±Ø¬ Ù…Ø§ ÙÙŠÙ‡Ø§"""
    prompt = """
    Analyze this image in detail.
    1. Extract all text/math exactly.
    2. Describe what kind of image it is (Math problem, Quran, General photo, Meme?).
    3. Output format:
       TYPE: [MATH/RELIGIOUS/GENERAL]
       CONTENT: [The extracted text]
       DESCRIPTION: [Brief description]
    """
    msgs = [{"role": "user", "content": [{"type": "text", "text": prompt}, {"type": "image_url", "image_url": {"url": image_url}}]}]
    try:
        return call_groq(msgs, MODEL_VISION, KEY_VISION)
    except:
        return None

def brain_process(user_id, user_text, image_context=None):
    """
    ğŸ§  Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…Ø¯Ø¨Ø±: ÙŠØ­Ø¯Ø¯ Ù†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø±Ø³Ù…ØŒ ØµÙˆØªØŒ Ø­Ù„ØŒ Ø¯Ø±Ø¯Ø´Ø©)
    """
    
    # Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¯Ø§Ø¦Ù…Ø© (System Prompt)
    system_prompt = f"""
    Ø£Ù†Øª "Ø¨ÙˆÙŠÙƒØªØ§" (Boykta)ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø¬Ø²Ø§Ø¦Ø±ÙŠ.
    
    ğŸ›‘ ØªØ¹Ù„ÙŠÙ…Ø§Øª ØµØ§Ø±Ù…Ø© (Intent Detection):
    1. Ø¥Ø°Ø§ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… **Ø±Ø³Ù… ØµÙˆØ±Ø©** (Ù…Ø«Ø§Ù„: "Ø§Ø±Ø³Ù… Ù‚Ø·Ø©", "ØªØ®ÙŠÙ„ Ù…Ù†Ø¸Ø±"):
       - Ø§Ø¨Ø¯Ø£ Ø±Ø¯Ùƒ Ø¨Ù€: CMD_IMAGE:
       - Ø«Ù… Ø§ÙƒØªØ¨ Ø§Ù„ÙˆØµÙ Ø§Ù„Ø¯Ù‚ÙŠÙ‚ Ù„Ù„ØµÙˆØ±Ø© **Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©**.
    
    2. Ø¥Ø°Ø§ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… **ØªØ­ÙˆÙŠÙ„ ÙƒÙ„Ø§Ù… Ù„ØµÙˆØª** (Ù…Ø«Ø§Ù„: "Ù‚Ù„ Ù‡Ø°Ø§ Ø¨ØµÙˆØª", "Ø§Ù‚Ø±Ø£ Ø§Ù„Ù†Øµ"):
       - Ø§Ø¨Ø¯Ø£ Ø±Ø¯Ùƒ Ø¨Ù€: CMD_AUDIO:
       - Ø«Ù… Ø§ÙƒØªØ¨ Ø§Ù„Ù†Øµ Ø§Ù„Ø°ÙŠ ÙŠØ¬Ø¨ Ù‚Ø±Ø§Ø¡ØªÙ‡.
    
    3. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ·Ù„Ø¨ **Ø­Ù„ ØªÙ…Ø±ÙŠÙ†** Ø£Ùˆ Ø´Ø±Ø­ Ù†Øµ (Ø®Ø§ØµØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø³ÙŠØ§Ù‚ ØµÙˆØ±Ø©):
       - Ø§Ø¨Ø¯Ø£ Ø±Ø¯Ùƒ Ø¨Ù€: CMD_SOLVE:
       - Ø«Ù… Ù‚Ù… Ø¨Ø­Ù„ Ø§Ù„ØªÙ…Ø±ÙŠÙ† Ø¨Ø§Ù„ØªÙØµÙŠÙ„ Ø§Ù„Ù…Ù…Ù„ (Ù…Ù†Ù‡Ø¬ Ø¬Ø²Ø§Ø¦Ø±ÙŠ) ÙˆØ§Ø³ØªØ®Ø¯Ù… LaTeX Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª.
       
    4. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø¯Ø±Ø¯Ø´Ø© Ø¹Ø§Ø¯ÙŠØ©:
       - Ø±Ø¯ Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ ÙˆÙˆØ¯ÙˆØ¯ Ø¨ØµÙØªÙƒ "Ø¨ÙˆÙŠÙƒØªØ§".
    
    â„¹ï¸ Ø³ÙŠØ§Ù‚ Ø¥Ø¶Ø§ÙÙŠ (Ù…Ø§Ø°Ø§ ÙŠÙˆØ¬Ø¯ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©): {image_context if image_context else "Ù„Ø§ ØªÙˆØ¬Ø¯ ØµÙˆØ±Ø© Ø­Ø§Ù„ÙŠØ§Ù‹"}
    """
    
    history = user_db[user_id]['history']
    history.append({"role": "user", "content": user_text})
    
    # Ø¥Ø¨Ù‚Ø§Ø¡ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù‚ØµÙŠØ±Ø© Ù„Ø¹Ø¯Ù… ØªØ´ØªÙŠØª Ø§Ù„Ø¨ÙˆØª
    messages = [{"role": "system", "content": system_prompt}] + history[-6:]
    
    try:
        reply = call_groq(messages, MODEL_CHAT, KEY_PRIMARY)
        
        # Ø­ÙØ¸ Ø§Ù„Ø±Ø¯ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ® (Ù…Ø§ Ø¹Ø¯Ø§ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ù„ÙƒÙŠ Ù„Ø§ ØªÙØ³Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚)
        if "CMD_" not in reply:
            history.append({"role": "assistant", "content": reply})
            
        return reply
    except:
        return "Ø¨ÙˆÙŠÙƒØªØ§ Ù…ØªØ¹Ø¨ Ù‚Ù„ÙŠÙ„Ø§Ù‹ØŒ Ø§Ù„Ø®ÙˆØ§Ø¯Ù… Ù…Ø´ØºÙˆÙ„Ø©."

# ====================================================================
# ğŸ“¨ Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
# ====================================================================

def send_msg(user_id, text):
    clean = text.replace('**', '').replace('__', '').replace('`', '')
    for chunk in textwrap.wrap(clean, 1900, replace_whitespace=False):
        requests.post(f"https://graph.facebook.com/v19.0/me/messages?access_token={PAGE_ACCESS_TOKEN}", 
                      json={'recipient': {'id': user_id}, 'message': {'text': chunk}})

def send_image_url(user_id, url):
    encoded_url = urllib.parse.quote(url, safe=':/?&=')
    requests.post(f"https://graph.facebook.com/v19.0/me/messages?access_token={PAGE_ACCESS_TOKEN}",
                  json={'recipient': {'id': user_id}, 'message': {'attachment': {'type': 'image', 'payload': {'url': encoded_url, 'is_reusable': True}}}})

def send_file_memory(user_id, data, type='image', filename='file.png', mime='image/png'):
    payload = {'recipient': json.dumps({'id': user_id}), 'message': json.dumps({'attachment': {'type': type, 'payload': {}}})}
    files = {'filedata': (filename, data, mime)}
    requests.post(f"https://graph.facebook.com/v19.0/me/messages?access_token={PAGE_ACCESS_TOKEN}", data=payload, files=files)

# ====================================================================
# ğŸ•¹ï¸ Ø§Ù„ØªØ­ÙƒÙ… (Controller)
# ====================================================================

@app.route('/webhook', methods=['GET', 'POST'])
def webhook():
    if request.method == 'GET':
        return request.args.get('hub.challenge') if request.args.get('hub.verify_token') == VERIFY_TOKEN else 'Error'
    if request.method == 'POST':
        try:
            data = request.get_json()
            if data['object'] == 'page':
                for entry in data['entry']:
                    for event in entry.get('messaging', []):
                        if 'message' in event:
                            handle_message(event['sender']['id'], event['message'])
        except Exception as e: logger.error(e)
        return 'ok'

def handle_message(user_id, msg):
    # 1. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± (Vision Intelligence)
    if 'attachments' in msg:
        if msg['attachments'][0]['type'] == 'image':
            url = msg['attachments'][0]['payload']['url']
            
            send_msg(user_id, "Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©... ğŸ‘ï¸")
            analysis = analyze_image(url)
            
            if analysis:
                user_db[user_id]['last_image_analysis'] = analysis
                user_db[user_id]['last_image_url'] = url
                
                # Ø§Ù„Ø±Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„ØµÙˆØ±Ø©
                if "MATH" in analysis or "Physics" in analysis:
                    send_msg(user_id, "Ø£Ø±Ù‰ ØªÙ…Ø±ÙŠÙ†Ø§Ù‹ Ø±ÙŠØ§Ø¶ÙŠØ§Ù‹/Ø¹Ù„Ù…ÙŠØ§Ù‹. ğŸ§®\nÙ‡Ù„ ØªØ±ÙŠØ¯Ù†ÙŠ Ø£Ù† Ø£Ø­Ù„Ù‡ Ù„ÙƒØŸ")
                elif "RELIGIOUS" in analysis:
                    send_msg(user_id, "ØµÙˆØ±Ø© Ø¯ÙŠÙ†ÙŠØ©/Ù†Øµ Ù‚Ø±Ø¢Ù†ÙŠ. ğŸ¤²\nÙ‡Ù„ ØªØ±ÙŠØ¯ ØªÙØ³ÙŠØ±Ø§Ù‹ Ø£Ùˆ Ù‚Ø±Ø§Ø¡Ø©ØŸ")
                else:
                    send_msg(user_id, "ÙˆØµÙ„Øª Ø§Ù„ØµÙˆØ±Ø©. Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ Ø£Ù† Ø£ÙØ¹Ù„ Ø¨Ù‡Ø§ØŸ (Ø­Ù„ØŒ ÙˆØµÙØŒ ØªØ±Ø¬Ù…Ø©...)")
            else:
                send_msg(user_id, "ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©.")
            return

    # 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©
    text = msg.get('text', '')
    if not text: return

    # Ø¥Ø­Ø¶Ø§Ø± Ø³ÙŠØ§Ù‚ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù† ÙˆØ¬Ø¯
    img_context = user_db[user_id]['last_image_analysis']
    
    # ğŸ§  Ø¥Ø±Ø³Ø§Ù„ ÙƒÙ„ Ø´ÙŠØ¡ Ù„Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…Ø¯Ø¨Ø±
    # (Ù†Ø¸Ù‡Ø± Ù…Ø¤Ø´Ø± Ø§Ù„ÙƒØªØ§Ø¨Ø© Ù„Ø¥Ø¹Ø·Ø§Ø¡ Ø´Ø¹ÙˆØ± Ø¨Ø§Ù„ØªÙÙƒÙŠØ±)
    requests.post(f"https://graph.facebook.com/v19.0/me/messages?access_token={PAGE_ACCESS_TOKEN}", 
                  json={'recipient': {'id': user_id}, 'sender_action': 'typing_on'})
    
    ai_response = brain_process(user_id, text, img_context)
    
    # --- ØªÙ†ÙÙŠØ° Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø­Ø³Ø¨ Ø±Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ ---
    
    # ğŸ¨ 1. Ø£Ù…Ø± Ø±Ø³Ù… ØµÙˆØ±Ø©
    if ai_response.startswith("CMD_IMAGE:"):
        prompt = ai_response.replace("CMD_IMAGE:", "").strip()
        send_msg(user_id, "Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±Ø³Ù…... ğŸ–Œï¸")
        try:
            seed = random.randint(1, 99999)
            url = f"https://image.pollinations.ai/prompt/{urllib.parse.quote(prompt)}?width=1024&height=1024&seed={seed}&model=flux"
            send_image_url(user_id, url)
        except:
            send_msg(user_id, "Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ù….")

    # ğŸ—£ï¸ 2. Ø£Ù…Ø± ØµÙˆØªÙŠ
    elif ai_response.startswith("CMD_AUDIO:"):
        tts_text = ai_response.replace("CMD_AUDIO:", "").strip()
        send_msg(user_id, "Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„... ğŸ™ï¸")
        try:
            fname = f"/tmp/voice_{user_id}_{random.randint(1,999)}.mp3"
            asyncio.run(edge_tts.Communicate(tts_text, "ar-EG-SalmaNeural").save(fname))
            with open(fname, 'rb') as f:
                requests.post(f"https://graph.facebook.com/v19.0/me/messages?access_token={PAGE_ACCESS_TOKEN}", 
                              data={'recipient': json.dumps({'id': user_id}), 'message': json.dumps({'attachment': {'type': 'audio', 'payload': {}}})}, 
                              files={'filedata': (fname, f, 'audio/mpeg')})
            os.remove(fname)
        except:
            send_msg(user_id, "ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØµÙˆØª.")

    # ğŸ§® 3. Ø£Ù…Ø± Ø­Ù„ (Ù…Ø¹Ø§Ø¯Ù„Ø§Øª ÙˆØµÙˆØ±)
    elif ai_response.startswith("CMD_SOLVE:"):
        solution = ai_response.replace("CMD_SOLVE:", "").strip()
        send_msg(user_id, "Ø¥Ù„ÙŠÙƒ Ø§Ù„Ø­Ù„ Ø§Ù„Ù…ÙØµÙ„ ğŸ‘‡")
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø­Ù„ Ù„ØµÙˆØ±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø¹Ù‚Ø¯Ø§Ù‹
        img_data = render_solution_to_image(solution)
        if img_data:
            send_file_memory(user_id, img_data, 'image', 'solution.png')
        else:
            send_msg(user_id, solution)

    # ğŸ’¬ 4. Ø¯Ø±Ø¯Ø´Ø© Ø¹Ø§Ø¯ÙŠØ©
    else:
        send_msg(user_id, ai_response)

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 25151))
    app.run(host='0.0.0.0', port=port)
