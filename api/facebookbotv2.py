import os
import json
import requests
import asyncio
import textwrap
import logging
import random
import urllib.parse
import io
import re
import matplotlib
# ÙˆØ¶Ø¹ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø§Ù„ØµØ§Ù…Øª Ù„Ù„Ø±Ø³Ù…
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from flask import Flask, request
from collections import defaultdict, deque
import edge_tts

# ====================================================================
# 1. âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (The Engine Room)
# ====================================================================
class Config:
    PORT = int(os.environ.get('PORT', 25151))
    VERIFY_TOKEN = 'boykta2025'
    PAGE_ACCESS_TOKEN = 'EAAYa4tM31ZAMBPZBZBIKE5832L12MHi04tWJOFSv4SzTY21FZCgc6KSnNvkSFDZBZAbUzDGn7NDSxzxERKXx57ZAxTod7B0mIyqfwpKF1NH8vzxu2Ahn16o7OCLSZCG8SvaJ3eDyFJPiqYq6z1TXxSb0OxZAF4vMY3vO20khvq6ZB1nCW4S6se2sxTCVezt1YiGLEZAWeK9'

    # ğŸ”’ ØªÙ… ÙØµÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù„ØªØ¬Ù†Ø¨ Ø­Ø¸Ø± GitHub
    # Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ù‡Ù†Ø§ Ù†Ø§Ù‚ØµØ© (Ø¨Ø¯ÙˆÙ† gsk_)
    _PARTIAL_KEYS = [
        "mwhCmwL1LNpcQvdMTHGvWGdyb3FYfU2hS7oMXV65vqEfROmTVr0q",
        "uKouecFAYlbnRuy0Nn2rWGdyb3FY15KRhNRZyQsBUBBugKcU8C2N",
        "jkVCijtNhFZ20uU7QTn5WGdyb3FYh2XK4b3uqYVoEN52Xjm9gN1d"
    ]
    
    MODEL_CHAT = "llama-3.1-8b-instant"
    VISION_MODELS = ["llama-3.2-11b-vision-preview", "llama-3.2-90b-vision-preview"]

    @staticmethod
    def get_key(index):
        # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØªØ§Ø­ Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„ ÙÙ‚Ø· Ù„Ø®Ø¯Ø§Ø¹ GitHub
        return "gsk_" + Config._PARTIAL_KEYS[index % len(Config._PARTIAL_KEYS)]

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(message)s')
logger = logging.getLogger("BoyktaBot_Final_Secure")

# ====================================================================
# 2. ğŸ§  Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¨ØµØ±ÙŠ ÙˆØ§Ù„Ù„ØºÙˆÙŠ (AI Core)
# ====================================================================
class AIService:
    def __init__(self):
        self.users = defaultdict(lambda: {'history': deque(maxlen=6), 'extracted_text': None})

    def _call_groq(self, messages, model, temp=0.5):
        """Ø¯Ø§Ù„Ø© Ø§ØªØµØ§Ù„ Ø¹Ø§Ù…Ø© Ù…Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØªØ¯ÙˆÙŠØ± Ø§Ù„Ù…ÙØ§ØªÙŠØ­"""
        for i in range(len(Config._PARTIAL_KEYS)):
            key = Config.get_key(i)
            try:
                headers = {"Authorization": f"Bearer {key}", "Content-Type": "application/json"}
                payload = {"model": model, "messages": messages, "temperature": temp}
                
                resp = requests.post("https://api.groq.com/openai/v1/chat/completions", 
                                   json=payload, headers=headers, timeout=30)
                
                if resp.status_code == 200:
                    return resp.json()['choices'][0]['message']['content']
                else:
                    logger.warning(f"Groq Fail ({model}): {resp.status_code}")
            except Exception as e:
                logger.error(f"Groq Error: {e}")
        return None

    def extract_text_from_image(self, user_id, img_url):
        """Ù…Ø­Ø±Ùƒ OCR Ø°ÙƒÙŠ: ÙŠØ­Ø§ÙˆÙ„ Ø¨Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹ØŒ Ø«Ù… Ø§Ù„Ù‚ÙˆÙŠ"""
        prompt = """
        SYSTEM: You are a strict OCR engine. 
        TASK: Extract ALL text, numbers, and mathematical formulas from this image exactly as they appear.
        OUTPUT: Just the text. No conversational filler like "Here is the text".
        """
        msg = [{"role": "user", "content": [{"type": "text", "text": prompt}, {"type": "image_url", "image_url": {"url": img_url}}]}]
        
        # 1. Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©
        extracted = self._call_groq(msg, Config.VISION_MODELS[0])
        
        # 2. Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù‚ÙˆÙŠØ© (Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø£ÙˆÙ„)
        if not extracted:
            logger.info("Switching to 90b model for better OCR...")
            extracted = self._call_groq(msg, Config.VISION_MODELS[1])

        if extracted:
            self.users[user_id]['extracted_text'] = extracted
            return True
        return False

    def chat_brain(self, user_id, user_input, task_type="chat"):
        user_data = self.users[user_id]
        context_text = user_data.get('extracted_text', '')

        if task_type == "solve":
            sys_prompt = f"""
            Ø£Ù†Øª Ù…Ø¯Ø±Ø³ Ø°ÙƒÙŠ. Ù„Ø¯ÙŠÙƒ Ù†Øµ ØªÙ…Ø±ÙŠÙ†:
            ---
            {context_text}
            ---
            Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: Ø­Ù„ Ø§Ù„ØªÙ…Ø±ÙŠÙ† Ø¨Ø§Ù„Ù…Ù†Ù‡Ø¬ Ø§Ù„Ø¬Ø²Ø§Ø¦Ø±ÙŠ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©.
            Ù‚Ø§Ø¹Ø¯Ø©: Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø±ÙŠØ§Ø¶ÙŠØ© Ø§ÙƒØªØ¨Ù‡Ø§ Ø¨ØµÙŠØºØ© LaTeX Ù…Ø­Ø§Ø·Ø© Ø¨Ù€ $$. Ù…Ø«Ø§Ù„: $$ x^2 $$
            """
        elif task_type == "translate":
            sys_prompt = f"ØªØ±Ø¬Ù… Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø¯Ù‚Ø©:\n{context_text}"
        else:
            sys_prompt = f"""
            Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ (Boykta).
            - Ù„Ù„Ø±Ø³Ù…: `CMD_IMAGE: <English Prompt>`
            - Ù„Ù„ØµÙˆØª: `CMD_AUDIO: <Text>`
            Ø³ÙŠØ§Ù‚ Ø³Ø§Ø¨Ù‚: {context_text}
            """

        msgs = [{"role": "system", "content": sys_prompt}] + list(user_data['history']) + [{"role": "user", "content": user_input}]
        
        reply = self._call_groq(msgs, Config.MODEL_CHAT)
        
        if reply and task_type == "chat" and "CMD_" not in reply:
            user_data['history'].append({"role": "user", "content": user_input})
            user_data['history'].append({"role": "assistant", "content": reply})
            
        return reply

ai = AIService()

# ====================================================================
# 3. ğŸ¨ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ÙˆØ³Ø§Ø¦Ø· (Media Tools)
# ====================================================================
class MediaTools:
    @staticmethod
    def render_latex(latex_formula):
        try:
            clean_tex = latex_formula.replace('$$', '').strip()
            fig, ax = plt.subplots(figsize=(8, 1.5))
            fig.patch.set_alpha(0)
            ax.axis('off')
            ax.text(0.5, 0.5, f"${clean_tex}$", size=20, ha='center', va='center')
            buf = io.BytesIO()
            plt.savefig(buf, format='png', bbox_inches='tight', dpi=150)
            plt.close(fig)
            buf.seek(0)
            return buf.getvalue()
        except: return None

    @staticmethod
    def get_image_bytes(prompt):
        try:
            safe_p = urllib.parse.quote(prompt)
            url = f"https://image.pollinations.ai/prompt/{safe_p}?width=1024&height=1024&model=flux&seed={random.randint(1,9999)}"
            return requests.get(url, timeout=25).content
        except: return None

    @staticmethod
    def text_to_speech(text):
        async def run():
            comm = edge_tts.Communicate(text, "ar-EG-SalmaNeural")
            out = io.BytesIO()
            async for chunk in comm.stream():
                if chunk["type"] == "audio": out.write(chunk["data"])
            out.seek(0)
            return out
        try: return asyncio.run(run())
        except: return None

# ====================================================================
# 4. ğŸŒ Ù…Ø¯ÙŠØ± Ø§Ù„ÙÙŠØ³Ø¨ÙˆÙƒ (Facebook Handler)
# ====================================================================
class FB:
    URL = "https://graph.facebook.com/v19.0/me/messages"
    
    @staticmethod
    def send(user_id, data):
        requests.post(f"{FB.URL}?access_token={Config.PAGE_ACCESS_TOKEN}", json=data)

    @staticmethod
    def typing(user_id):
        FB.send(user_id, {'recipient': {'id': user_id}, 'sender_action': 'typing_on'})

    @staticmethod
    def text(user_id, msg, quick_replies=None):
        payload = {'recipient': {'id': user_id}, 'message': {'text': msg}}
        if quick_replies:
            payload['message']['quick_replies'] = [{"content_type": "text", "title": k, "payload": v} for k, v in quick_replies.items()]
        FB.send(user_id, payload)

    @staticmethod
    def file(user_id, file_data, type='image'):
        files = {'filedata': ('f.png' if type=='image' else 'f.mp3', file_data, 'image/png' if type=='image' else 'audio/mpeg')}
        payload = {'recipient': json.dumps({'id': user_id}), 'message': json.dumps({'attachment': {'type': type, 'payload': {}}})}
        requests.post(f"{FB.URL}?access_token={Config.PAGE_ACCESS_TOKEN}", data=payload, files=files)

# ====================================================================
# 5. ğŸ® Ø§Ù„ØªØ­ÙƒÙ… (Controller)
# ====================================================================
app = Flask(__name__)

@app.route('/webhook', methods=['GET', 'POST'])
def webhook():
    if request.method == 'GET':
        return request.args.get('hub.challenge') if request.args.get('hub.verify_token') == Config.VERIFY_TOKEN else 'Error'

    if request.method == 'POST':
        data = request.get_json()
        if data['object'] == 'page':
            for entry in data['entry']:
                for event in entry.get('messaging', []):
                    if 'message' in event:
                        process(event['sender']['id'], event['message'])
        return 'OK'

def process(uid, msg):
    FB.typing(uid)

    if msg.get('sticker_id'):
        FB.text(uid, "ğŸ‘")
        return

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
    if 'attachments' in msg and msg['attachments'][0]['type'] == 'image':
        if msg.get('sticker_id'): return
        url = msg['attachments'][0]['payload']['url']
        FB.text(uid, "Ù„Ø­Ø¸Ø©ØŒ Ø£Ù‚Ø±Ø£ Ø§Ù„ØµÙˆØ±Ø© Ø¯Ø§Ø®Ù„ÙŠØ§Ù‹... ğŸ‘ï¸")
        
        if ai.extract_text_from_image(uid, url):
            btns = {"ğŸ“ Ø­Ù„ Ø§Ù„ØªÙ…Ø±ÙŠÙ†": "cmd_solve", "ğŸ‡¬ğŸ‡§ ØªØ±Ø¬Ù…Ø©": "cmd_translate", "ğŸ“„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ": "cmd_extract"}
            FB.text(uid, "ØªÙ… Ø§Ù„Ù‚Ø±Ø§Ø¡Ø©! Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ØŸ", quick_replies=btns)
        else:
            FB.text(uid, "ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ØµÙˆØ±Ø©ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.")
        return

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ
    text = msg.get('text')
    if not text: return

    if text == "cmd_solve":
        FB.text(uid, "Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø­Ù„... ğŸ“")
        solution = ai.chat_brain(uid, "Ø­Ù„ Ø§Ù„ØªÙ…Ø±ÙŠÙ†", "solve")
        parts = re.split(r'(\$\$.*?\$\$)', solution, flags=re.DOTALL)
        for part in parts:
            if part.startswith('$$'):
                img = MediaTools.render_latex(part)
                if img: FB.file(uid, img, 'image')
            elif part.strip():
                FB.text(uid, part.strip())
        return

    elif text == "cmd_translate":
        FB.text(uid, "Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ±Ø¬Ù…Ø©...")
        FB.text(uid, ai.chat_brain(uid, "ØªØ±Ø¬Ù…", "translate"))
        return

    elif text == "cmd_extract":
        FB.text(uid, ai.users[uid].get('extracted_text', "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Øµ."))
        return

    # Ù…Ø­Ø§Ø¯Ø«Ø© Ø¹Ø§Ø¯ÙŠØ©
    reply = ai.chat_brain(uid, text)
    
    if "CMD_IMAGE:" in reply:
        FB.text(uid, "Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±Ø³Ù…... ğŸ¨")
        img = MediaTools.get_image_bytes(reply.split("CMD_IMAGE:")[1].strip())
        if img: FB.file(uid, img, 'image')
        else: FB.text(uid, "ÙØ´Ù„ Ø§Ù„Ø±Ø³Ù….")
        
    elif "CMD_AUDIO:" in reply:
        FB.text(uid, "ØªØ³Ø¬ÙŠÙ„... ğŸ™ï¸")
        aud = MediaTools.text_to_speech(reply.split("CMD_AUDIO:")[1].strip())
        if aud: FB.file(uid, aud, 'audio')
        
    elif "CMD_MATH:" in reply:
        img = MediaTools.render_latex(reply.split("CMD_MATH:")[1].strip())
        if img: FB.file(uid, img, 'image')
        
    else:
        FB.text(uid, reply)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=Config.PORT)
